{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Function\n",
    "\n",
    "You will see these at the top of every module.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = f\"{name}-{tv}\"\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name ,main=None):\n",
    "    newOutcome = []\n",
    "    if main is not None:\n",
    "        for other in df[name]:\n",
    "            if other != main:\n",
    "                newOutcome.append(\"other\")\n",
    "            else:\n",
    "                newOutcome.append(main)\n",
    "        df[name] = newOutcome\n",
    "    #print(df[name][490950:491050])           \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        \n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\"\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n",
    "                          >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The KDD-99 Dataset\n",
    "\n",
    "The KDD-99 dataset is very famous in the security field and almost a \"hello world\" of intrusion detection systems in machine learning.\n",
    "\n",
    "# Read in Raw KDD-99 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 494021 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>159</td>\n",
       "      <td>4087</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>210</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "5         0           tcp    http   SF        217       2032     0   \n",
       "6         0           tcp    http   SF        212       1940     0   \n",
       "7         0           tcp    http   SF        159       4087     0   \n",
       "8         0           tcp    http   SF        210        151     0   \n",
       "9         0           tcp    http   SF        212        786     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  num_failed_logins  num_compromised  \\\n",
       "0               0       0    0                  0                0   \n",
       "1               0       0    0                  0                0   \n",
       "2               0       0    0                  0                0   \n",
       "3               0       0    0                  0                0   \n",
       "4               0       0    0                  0                0   \n",
       "5               0       0    0                  0                0   \n",
       "6               0       0    0                  0                0   \n",
       "7               0       0    0                  0                0   \n",
       "8               0       0    0                  0                0   \n",
       "9               0       0    1                  0                0   \n",
       "\n",
       "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
       "0           0             0         0                   0           0   \n",
       "1           0             0         0                   0           0   \n",
       "2           0             0         0                   0           0   \n",
       "3           0             0         0                   0           0   \n",
       "4           0             0         0                   0           0   \n",
       "5           0             0         0                   0           0   \n",
       "6           0             0         0                   0           0   \n",
       "7           0             0         0                   0           0   \n",
       "8           0             0         0                   0           0   \n",
       "9           0             0         0                   0           0   \n",
       "\n",
       "   num_access_files  num_outbound_cmds  count  srv_count  serror_rate  \\\n",
       "0                 0                  0      8          8          0.0   \n",
       "1                 0                  0      8          8          0.0   \n",
       "2                 0                  0      8          8          0.0   \n",
       "3                 0                  0      6          6          0.0   \n",
       "4                 0                  0      6          6          0.0   \n",
       "5                 0                  0      6          6          0.0   \n",
       "6                 0                  0      1          2          0.0   \n",
       "7                 0                  0      5          5          0.0   \n",
       "8                 0                  0      8          8          0.0   \n",
       "9                 0                  0      8          8          0.0   \n",
       "\n",
       "   srv_serror_rate  rerror_rate  srv_rerror_rate  same_srv_rate  \\\n",
       "0              0.0          0.0              0.0            1.0   \n",
       "1              0.0          0.0              0.0            1.0   \n",
       "2              0.0          0.0              0.0            1.0   \n",
       "3              0.0          0.0              0.0            1.0   \n",
       "4              0.0          0.0              0.0            1.0   \n",
       "5              0.0          0.0              0.0            1.0   \n",
       "6              0.0          0.0              0.0            1.0   \n",
       "7              0.0          0.0              0.0            1.0   \n",
       "8              0.0          0.0              0.0            1.0   \n",
       "9              0.0          0.0              0.0            1.0   \n",
       "\n",
       "   diff_srv_rate  srv_diff_host_rate  dst_host_count  dst_host_srv_count  \\\n",
       "0            0.0                 0.0               9                   9   \n",
       "1            0.0                 0.0              19                  19   \n",
       "2            0.0                 0.0              29                  29   \n",
       "3            0.0                 0.0              39                  39   \n",
       "4            0.0                 0.0              49                  49   \n",
       "5            0.0                 0.0              59                  59   \n",
       "6            0.0                 1.0               1                  69   \n",
       "7            0.0                 0.0              11                  79   \n",
       "8            0.0                 0.0               8                  89   \n",
       "9            0.0                 0.0               8                  99   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "5                     1.0                     0.0   \n",
       "6                     1.0                     0.0   \n",
       "7                     1.0                     0.0   \n",
       "8                     1.0                     0.0   \n",
       "9                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                         0.00   \n",
       "1                         0.05                         0.00   \n",
       "2                         0.03                         0.00   \n",
       "3                         0.03                         0.00   \n",
       "4                         0.02                         0.00   \n",
       "5                         0.02                         0.00   \n",
       "6                         1.00                         0.04   \n",
       "7                         0.09                         0.04   \n",
       "8                         0.12                         0.04   \n",
       "9                         0.12                         0.05   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "5                   0.0                       0.0                   0.0   \n",
       "6                   0.0                       0.0                   0.0   \n",
       "7                   0.0                       0.0                   0.0   \n",
       "8                   0.0                       0.0                   0.0   \n",
       "9                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  outcome  \n",
       "0                       0.0  normal.  \n",
       "1                       0.0  normal.  \n",
       "2                       0.0  normal.  \n",
       "3                       0.0  normal.  \n",
       "4                       0.0  normal.  \n",
       "5                       0.0  normal.  \n",
       "6                       0.0  normal.  \n",
       "7                       0.0  normal.  \n",
       "8                       0.0  normal.  \n",
       "9                       0.0  normal.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import pandas as pd\n",
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "\n",
    "#C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\N.T.T.D-with-M.L\\\\Traning set\\\\KDD-99\\\\kddcup.data_10_percent_corrected\n",
    "#D:\\\\training set\\\\kdd data set\\\\kddcup.data.corrected\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\N.T.T.D-with-M.L\\\\Traning set\\\\KDD-99\\\\kddcup.data_10_percent_corrected\", header=None)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "df = df.drop(columns=['is_host_login' , 'is_guest_login' , 'logged_in'])\n",
    "# display 5 rows\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df[(df['outcome'] == 'normal.') | (df['outcome'] == 'smurf.')][0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the feature vector\n",
    "\n",
    "Encode every row in the database. This is not instant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386820 107201 494021\n",
      "---------------\n",
      "['other']\n",
      "---------------\n",
      "['normal.' 'other']\n",
      "---------------\n",
      "['normal.' 'other']\n"
     ]
    }
   ],
   "source": [
    "# Now encode the feature vector\n",
    "\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "encode_text_dummy(df, 'protocol_type')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'flag')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_text_dummy(df, 'land')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "#encode_text_dummy(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'num_compromised')\n",
    "encode_numeric_zscore(df, 'root_shell')\n",
    "encode_numeric_zscore(df, 'su_attempted')\n",
    "encode_numeric_zscore(df, 'num_root')\n",
    "encode_numeric_zscore(df, 'num_file_creations')\n",
    "encode_numeric_zscore(df, 'num_shells')\n",
    "encode_numeric_zscore(df, 'num_access_files')\n",
    "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "#encode_text_dummy(df, 'is_host_login')\n",
    "#encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "#(df['outcome'] == 'smurf.') | (df['outcome'] == 'buffer_overflow.') | (df['outcome'] == 'warezmaster.')\n",
    "drop = df.drop(df[(df['outcome'] == 'neptune.')].index).copy()\n",
    "complete = df[(df['outcome'] == 'neptune.')].copy()\n",
    "print(len(drop),len(complete),len(df))\n",
    "outcomes = encode_text_index(complete, 'outcome',\"normal.\")\n",
    "print(\"---------------\")\n",
    "print(outcomes)\n",
    "# display 5 rows\n",
    "complete.dropna(inplace=True,axis=1)\n",
    "outcomes2 = encode_text_index(drop, 'outcome',\"normal.\")\n",
    "print(\"---------------\")\n",
    "print(outcomes2)\n",
    "# display 5 rows\n",
    "drop.dropna(inplace=True,axis=1)\n",
    "\n",
    "outcomes3 = encode_text_index(df, 'outcome',\"normal.\")\n",
    "print(\"---------------\")\n",
    "print(outcomes3)\n",
    "# display 5 rows\n",
    "df.dropna(inplace=True,axis=1)\n",
    "# This is the numeric feature vector, as it goes to the neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepering the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290115, 115)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(290115, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "from keras import regularizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(drop,'outcome')\n",
    "x2, y2 = to_xy(complete,'outcome')\n",
    "x3, y3 = to_xy(df,'outcome')\n",
    "\n",
    "y2 = np.c_[np.zeros((len(y2),1)),y2]\n",
    "#y = np.c_[y,np.zeros((len(y),1))]\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y)\n",
    "print(y2)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "class Overfit(Callback):\n",
    "    def __init__(self,model,test_data, test_train_data):\n",
    "        self.model = model\n",
    "        self.test,self.result  = test_data\n",
    "        self.train_test,self.train_result = test_train_data\n",
    "        self.score_log_valid = []\n",
    "        self.score_log_training = []\n",
    "        self.batch_session = {valid : [], train : []}\n",
    "        self.batch_log = {valid : [], train : []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        pred = self.model.predict(self.test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.score_log_valid.append(score)\n",
    "        \n",
    "        pred = self.model.predict(self.train_test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.train_result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.score_log_training.append(score)\n",
    "        \n",
    "        self.batch_log['valid'].append(self.batch_session)\n",
    "        self.batch_log['train'].append(self.batch_session)\n",
    "        self.batch_session = {valid : [], train : []}\n",
    "        \n",
    "    #def on_batch_begin(self, batch, logs = {}) :\n",
    "        #print(logs)\n",
    "        \n",
    "    def on_batch_end(self, batch, logs = {}):\n",
    "        pred = self.model.predict(self.train_test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.train_result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.batch_session['train'].append(score)\n",
    "        \n",
    "        pred = self.model.predict(self.test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.batch_session['valid'].append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 290115 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 42s - loss: 0.6830 - val_loss: 0.6697\n",
      "Epoch 2/1000\n",
      " - 41s - loss: 0.6465 - val_loss: 0.5968\n",
      "Epoch 3/1000\n",
      " - 42s - loss: 0.5022 - val_loss: 0.3920\n",
      "Epoch 4/1000\n",
      " - 43s - loss: 0.2579 - val_loss: 0.1005\n",
      "Epoch 5/1000\n",
      " - 41s - loss: 0.0512 - val_loss: 0.0274\n",
      "Epoch 6/1000\n",
      " - 42s - loss: 0.0220 - val_loss: 0.0178\n",
      "Epoch 7/1000\n",
      " - 41s - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 8/1000\n",
      " - 41s - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 9/1000\n",
      " - 42s - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 10/1000\n",
      " - 41s - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 11/1000\n",
      " - 42s - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 12/1000\n",
      " - 43s - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 13/1000\n",
      " - 42s - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 14/1000\n",
      " - 42s - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 15/1000\n",
      " - 42s - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 16/1000\n",
      " - 41s - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 17/1000\n",
      " - 41s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 18/1000\n",
      " - 42s - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 19/1000\n",
      " - 41s - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 20/1000\n",
      " - 41s - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 21/1000\n",
      " - 43s - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 22/1000\n",
      " - 43s - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 23/1000\n",
      " - 44s - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create neural net Aproch B\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath = \"best_weights.hdf5\" , verbose = 0, save_best_only=True)\n",
    "step = Overfit(model,(x3,x3),(x_train,y_train))\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer,step],verbose=2,epochs=1000,batch_size = 10000)\n",
    "model.load_weights('best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_data': [array([[-0.06779165, -0.00201738, -0.0262873 , ...,  0.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [-0.06779165, -0.00201738, -0.0262873 , ...,  0.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [-0.06779165, -0.00201738, -0.0262873 , ...,  0.        ,\n",
       "           1.        ,  0.        ],\n",
       "         ...,\n",
       "         [-0.06779165, -0.00201738, -0.0262873 , ...,  0.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [-0.06779165, -0.00201738, -0.0262873 , ...,  0.        ,\n",
       "           1.        ,  0.        ],\n",
       "         [-0.06779165, -0.00201738, -0.0262873 , ...,  0.        ,\n",
       "           1.        ,  0.        ]], dtype=float32), array([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         ...,\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=float32), array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)],\n",
       " 'model': <keras.engine.sequential.Sequential at 0x23c83d3f7b8>,\n",
       " 'params': {'batch_size': 10000,\n",
       "  'epochs': 1000,\n",
       "  'steps': None,\n",
       "  'samples': 290115,\n",
       "  'verbose': 2,\n",
       "  'do_validation': True,\n",
       "  'metrics': ['loss', 'val_loss']},\n",
       " 'epoch': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22],\n",
       " 'history': {'val_loss': [0.6697148094471371,\n",
       "   0.5968299745638143,\n",
       "   0.39203763159741095,\n",
       "   0.10047366504113607,\n",
       "   0.027359753912706255,\n",
       "   0.017808434586525333,\n",
       "   0.013664102666353506,\n",
       "   0.011301600898472377,\n",
       "   0.009771131013682963,\n",
       "   0.008670898507674754,\n",
       "   0.007791417912877609,\n",
       "   0.006992920213590597,\n",
       "   0.006384090460202427,\n",
       "   0.005954149032944733,\n",
       "   0.005641961018236336,\n",
       "   0.005398381521804852,\n",
       "   0.005236622421966093,\n",
       "   0.0049435592800468175,\n",
       "   0.004810450862378358,\n",
       "   0.004724323537188555,\n",
       "   0.004585606256737472,\n",
       "   0.004630014783619535,\n",
       "   0.004469619041088124],\n",
       "  'loss': [0.6830291593464951,\n",
       "   0.6464729814647513,\n",
       "   0.5021573060596154,\n",
       "   0.2579054909908683,\n",
       "   0.05124381298943963,\n",
       "   0.022023178905206525,\n",
       "   0.01552584067544743,\n",
       "   0.01238896384108586,\n",
       "   0.01049966220672969,\n",
       "   0.009135808630943886,\n",
       "   0.008211428611126715,\n",
       "   0.00733876837657573,\n",
       "   0.006597785157067462,\n",
       "   0.006026456912148463,\n",
       "   0.005615066285520474,\n",
       "   0.005530200897587947,\n",
       "   0.005165504802618644,\n",
       "   0.00487323143824541,\n",
       "   0.004643433453303192,\n",
       "   0.004407952262680197,\n",
       "   0.004316116165385407,\n",
       "   0.004165463343410598,\n",
       "   0.0042747710134472166]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting & Underfitting Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
