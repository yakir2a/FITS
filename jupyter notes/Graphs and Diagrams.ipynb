{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Function\n",
    "\n",
    "You will see these at the top of every module.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = f\"{name}-{tv}\"\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name ,main=None):\n",
    "    newOutcome = []\n",
    "    if main is not None:\n",
    "        for other in df[name]:\n",
    "            if other != main:\n",
    "                newOutcome.append(\"other\")\n",
    "            else:\n",
    "                newOutcome.append(main)\n",
    "        df[name] = newOutcome\n",
    "    #print(df[name][490950:491050])           \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        \n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\"\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n",
    "                          >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The KDD-99 Dataset\n",
    "\n",
    "The KDD-99 dataset is very famous in the security field and almost a \"hello world\" of intrusion detection systems in machine learning.\n",
    "\n",
    "# Read in Raw KDD-99 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 494021 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>159</td>\n",
       "      <td>4087</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>210</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "5         0           tcp    http   SF        217       2032     0   \n",
       "6         0           tcp    http   SF        212       1940     0   \n",
       "7         0           tcp    http   SF        159       4087     0   \n",
       "8         0           tcp    http   SF        210        151     0   \n",
       "9         0           tcp    http   SF        212        786     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  num_failed_logins  num_compromised  \\\n",
       "0               0       0    0                  0                0   \n",
       "1               0       0    0                  0                0   \n",
       "2               0       0    0                  0                0   \n",
       "3               0       0    0                  0                0   \n",
       "4               0       0    0                  0                0   \n",
       "5               0       0    0                  0                0   \n",
       "6               0       0    0                  0                0   \n",
       "7               0       0    0                  0                0   \n",
       "8               0       0    0                  0                0   \n",
       "9               0       0    1                  0                0   \n",
       "\n",
       "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
       "0           0             0         0                   0           0   \n",
       "1           0             0         0                   0           0   \n",
       "2           0             0         0                   0           0   \n",
       "3           0             0         0                   0           0   \n",
       "4           0             0         0                   0           0   \n",
       "5           0             0         0                   0           0   \n",
       "6           0             0         0                   0           0   \n",
       "7           0             0         0                   0           0   \n",
       "8           0             0         0                   0           0   \n",
       "9           0             0         0                   0           0   \n",
       "\n",
       "   num_access_files  num_outbound_cmds  count  srv_count  serror_rate  \\\n",
       "0                 0                  0      8          8          0.0   \n",
       "1                 0                  0      8          8          0.0   \n",
       "2                 0                  0      8          8          0.0   \n",
       "3                 0                  0      6          6          0.0   \n",
       "4                 0                  0      6          6          0.0   \n",
       "5                 0                  0      6          6          0.0   \n",
       "6                 0                  0      1          2          0.0   \n",
       "7                 0                  0      5          5          0.0   \n",
       "8                 0                  0      8          8          0.0   \n",
       "9                 0                  0      8          8          0.0   \n",
       "\n",
       "   srv_serror_rate  rerror_rate  srv_rerror_rate  same_srv_rate  \\\n",
       "0              0.0          0.0              0.0            1.0   \n",
       "1              0.0          0.0              0.0            1.0   \n",
       "2              0.0          0.0              0.0            1.0   \n",
       "3              0.0          0.0              0.0            1.0   \n",
       "4              0.0          0.0              0.0            1.0   \n",
       "5              0.0          0.0              0.0            1.0   \n",
       "6              0.0          0.0              0.0            1.0   \n",
       "7              0.0          0.0              0.0            1.0   \n",
       "8              0.0          0.0              0.0            1.0   \n",
       "9              0.0          0.0              0.0            1.0   \n",
       "\n",
       "   diff_srv_rate  srv_diff_host_rate  dst_host_count  dst_host_srv_count  \\\n",
       "0            0.0                 0.0               9                   9   \n",
       "1            0.0                 0.0              19                  19   \n",
       "2            0.0                 0.0              29                  29   \n",
       "3            0.0                 0.0              39                  39   \n",
       "4            0.0                 0.0              49                  49   \n",
       "5            0.0                 0.0              59                  59   \n",
       "6            0.0                 1.0               1                  69   \n",
       "7            0.0                 0.0              11                  79   \n",
       "8            0.0                 0.0               8                  89   \n",
       "9            0.0                 0.0               8                  99   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "5                     1.0                     0.0   \n",
       "6                     1.0                     0.0   \n",
       "7                     1.0                     0.0   \n",
       "8                     1.0                     0.0   \n",
       "9                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                         0.00   \n",
       "1                         0.05                         0.00   \n",
       "2                         0.03                         0.00   \n",
       "3                         0.03                         0.00   \n",
       "4                         0.02                         0.00   \n",
       "5                         0.02                         0.00   \n",
       "6                         1.00                         0.04   \n",
       "7                         0.09                         0.04   \n",
       "8                         0.12                         0.04   \n",
       "9                         0.12                         0.05   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "5                   0.0                       0.0                   0.0   \n",
       "6                   0.0                       0.0                   0.0   \n",
       "7                   0.0                       0.0                   0.0   \n",
       "8                   0.0                       0.0                   0.0   \n",
       "9                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  outcome  \n",
       "0                       0.0  normal.  \n",
       "1                       0.0  normal.  \n",
       "2                       0.0  normal.  \n",
       "3                       0.0  normal.  \n",
       "4                       0.0  normal.  \n",
       "5                       0.0  normal.  \n",
       "6                       0.0  normal.  \n",
       "7                       0.0  normal.  \n",
       "8                       0.0  normal.  \n",
       "9                       0.0  normal.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import pandas as pd\n",
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "\n",
    "#C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\N.T.T.D-with-M.L\\\\Traning set\\\\KDD-99\\\\kddcup.data_10_percent_corrected\n",
    "#D:\\\\training set\\\\kdd data set\\\\kddcup.data.corrected\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\N.T.T.D-with-M.L\\\\Traning set\\\\KDD-99\\\\kddcup.data_10_percent_corrected\", header=None)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "df = df.drop(columns=['is_host_login' , 'is_guest_login' , 'logged_in'])\n",
    "# display 5 rows\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df[(df['outcome'] == 'normal.') | (df['outcome'] == 'smurf.')][0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the feature vector\n",
    "\n",
    "Encode every row in the database. This is not instant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386820 107201 494021\n",
      "---------------\n",
      "['other']\n",
      "---------------\n",
      "['normal.' 'other']\n",
      "---------------\n",
      "['normal.' 'other']\n"
     ]
    }
   ],
   "source": [
    "# Now encode the feature vector\n",
    "\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "encode_text_dummy(df, 'protocol_type')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'flag')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_text_dummy(df, 'land')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "#encode_text_dummy(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'num_compromised')\n",
    "encode_numeric_zscore(df, 'root_shell')\n",
    "encode_numeric_zscore(df, 'su_attempted')\n",
    "encode_numeric_zscore(df, 'num_root')\n",
    "encode_numeric_zscore(df, 'num_file_creations')\n",
    "encode_numeric_zscore(df, 'num_shells')\n",
    "encode_numeric_zscore(df, 'num_access_files')\n",
    "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "#encode_text_dummy(df, 'is_host_login')\n",
    "#encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "#(df['outcome'] == 'smurf.') | (df['outcome'] == 'buffer_overflow.') | (df['outcome'] == 'warezmaster.')\n",
    "drop = df.drop(df[(df['outcome'] == 'neptune.')].index).copy()\n",
    "complete = df[(df['outcome'] == 'neptune.')].copy()\n",
    "print(len(drop),len(complete),len(df))\n",
    "outcomes = encode_text_index(complete, 'outcome',\"normal.\")\n",
    "print(\"---------------\")\n",
    "print(outcomes)\n",
    "# display 5 rows\n",
    "complete.dropna(inplace=True,axis=1)\n",
    "outcomes2 = encode_text_index(drop, 'outcome',\"normal.\")\n",
    "print(\"---------------\")\n",
    "print(outcomes2)\n",
    "# display 5 rows\n",
    "drop.dropna(inplace=True,axis=1)\n",
    "\n",
    "outcomes3 = encode_text_index(df, 'outcome',\"normal.\")\n",
    "print(\"---------------\")\n",
    "print(outcomes3)\n",
    "# display 5 rows\n",
    "df.dropna(inplace=True,axis=1)\n",
    "# This is the numeric feature vector, as it goes to the neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepering the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290115, 115)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(290115, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "from keras import regularizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(drop,'outcome')\n",
    "x2, y2 = to_xy(complete,'outcome')\n",
    "x3, y3 = to_xy(df,'outcome')\n",
    "\n",
    "y2 = np.c_[np.zeros((len(y2),1)),y2]\n",
    "#y = np.c_[y,np.zeros((len(y),1))]\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y)\n",
    "print(y2)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "class Overfit(Callback):\n",
    "    def __init__(self,model,test_data, test_train_data):\n",
    "        self.model = model\n",
    "        self.test,self.result  = test_data\n",
    "        self.train_test,self.train_result = test_train_data\n",
    "        self.score_log_valid = []\n",
    "        self.score_log_training = []\n",
    "        self.batch_session = {'valid' : [], 'train' : []}\n",
    "        self.batch_log = {'valid' : [], 'train' : []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        pred = self.model.predict(self.test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.score_log_valid.append(score)\n",
    "        \n",
    "        pred = self.model.predict(self.train_test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.train_result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.score_log_training.append(score)\n",
    "        \n",
    "        #self.batch_log['valid'].append(self.batch_session)\n",
    "        #self.batch_log['train'].append(self.batch_session)\n",
    "        #self.batch_session = {'valid' : [], 'train' : []}\n",
    "        \n",
    "    #def on_batch_begin(self, batch, logs = {}) :\n",
    "        #print(logs)\n",
    "        \n",
    "    def on_batch_end(self, batch, logs = {}):\n",
    "        print(batch)\n",
    "        '''\n",
    "        pred = self.model.predict(self.train_test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(self.train_result,axis=1)\n",
    "        score = metrics.accuracy_score(y_test2, pred)\n",
    "        self.batch_session['train'].append(score)\n",
    "        '''\n",
    "        \n",
    "def scroe(model,test,result):\n",
    "        pred = model.predict(test)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        y_test2 = np.argmax(result,axis=1)\n",
    "        score = 1-metrics.accuracy_score(y_test2, pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14505 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 4s - loss: 0.1662 - val_loss: 0.0201\n",
      "Epoch 2/1000\n",
      " - 3s - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 3/1000\n",
      " - 3s - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 4/1000\n",
      " - 3s - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 5/1000\n",
      " - 3s - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 6/1000\n",
      " - 3s - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 7/1000\n",
      " - 3s - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 8/1000\n",
      " - 3s - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 9/1000\n",
      " - 3s - loss: 0.0022 - val_loss: 0.0076\n",
      "Epoch 00009: early stopping\n",
      "Train on 29010 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 4s - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 2/1000\n",
      " - 4s - loss: 0.0042 - val_loss: 0.0083\n",
      "Epoch 3/1000\n",
      " - 4s - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 4/1000\n",
      " - 4s - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 5/1000\n",
      " - 4s - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 6/1000\n",
      " - 4s - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 00006: early stopping\n",
      "Train on 43515 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 0.0038 - val_loss: 0.0072\n",
      "Epoch 2/1000\n",
      " - 5s - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 3/1000\n",
      " - 5s - loss: 0.0032 - val_loss: 0.0070\n",
      "Epoch 4/1000\n",
      " - 5s - loss: 0.0028 - val_loss: 0.0065\n",
      "Epoch 5/1000\n",
      " - 5s - loss: 0.0026 - val_loss: 0.0069\n",
      "Epoch 6/1000\n",
      " - 5s - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 7/1000\n",
      " - 5s - loss: 0.0029 - val_loss: 0.0077\n",
      "Epoch 00007: early stopping\n",
      "Train on 58020 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 6s - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 2/1000\n",
      " - 6s - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 3/1000\n",
      " - 6s - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 4/1000\n",
      " - 6s - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 5/1000\n",
      " - 7s - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 6/1000\n",
      " - 6s - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 7/1000\n",
      " - 6s - loss: 0.0023 - val_loss: 0.0084\n",
      "Epoch 00007: early stopping\n",
      "Train on 72525 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 8s - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 2/1000\n",
      " - 8s - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 3/1000\n",
      " - 8s - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 4/1000\n",
      " - 8s - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 5/1000\n",
      " - 8s - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 6/1000\n",
      " - 8s - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 7/1000\n",
      " - 8s - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 00007: early stopping\n",
      "Train on 87030 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 9s - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 2/1000\n",
      " - 9s - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 3/1000\n",
      " - 9s - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 4/1000\n",
      " - 9s - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 5/1000\n",
      " - 9s - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 6/1000\n",
      " - 9s - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 00006: early stopping\n",
      "Train on 101535 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 10s - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 2/1000\n",
      " - 10s - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 3/1000\n",
      " - 10s - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 4/1000\n",
      " - 10s - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 5/1000\n",
      " - 10s - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 6/1000\n",
      " - 10s - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 00006: early stopping\n",
      "Train on 116040 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 11s - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 2/1000\n",
      " - 11s - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 3/1000\n",
      " - 11s - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 4/1000\n",
      " - 11s - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 5/1000\n",
      " - 11s - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 6/1000\n",
      " - 11s - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 00006: early stopping\n",
      "Train on 130545 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 12s - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 2/1000\n",
      " - 12s - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 3/1000\n",
      " - 12s - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 4/1000\n",
      " - 12s - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 5/1000\n",
      " - 12s - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 6/1000\n",
      " - 12s - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 00006: early stopping\n",
      "Train on 145050 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 13s - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 2/1000\n",
      " - 13s - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 3/1000\n",
      " - 13s - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 4/1000\n",
      " - 13s - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 5/1000\n",
      " - 13s - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 6/1000\n",
      " - 13s - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 00006: early stopping\n",
      "Train on 159555 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 15s - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 2/1000\n",
      " - 14s - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 3/1000\n",
      " - 14s - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 4/1000\n",
      " - 14s - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 5/1000\n",
      " - 14s - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 6/1000\n",
      " - 14s - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 00006: early stopping\n",
      "Train on 174060 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 16s - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 2/1000\n",
      " - 16s - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 3/1000\n",
      " - 16s - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 4/1000\n",
      " - 16s - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 5/1000\n",
      " - 16s - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 6/1000\n",
      " - 16s - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 00006: early stopping\n",
      "Train on 188565 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 17s - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 2/1000\n",
      " - 17s - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 3/1000\n",
      " - 17s - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 4/1000\n",
      " - 17s - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 5/1000\n",
      " - 17s - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 6/1000\n",
      " - 17s - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 00006: early stopping\n",
      "Train on 203070 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 18s - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 2/1000\n",
      " - 18s - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 3/1000\n",
      " - 18s - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 4/1000\n",
      " - 18s - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 5/1000\n",
      " - 18s - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 6/1000\n",
      " - 18s - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 00006: early stopping\n",
      "Train on 217575 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 19s - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 2/1000\n",
      " - 19s - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 3/1000\n",
      " - 19s - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 4/1000\n",
      " - 19s - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 5/1000\n",
      " - 19s - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 6/1000\n",
      " - 19s - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 00006: early stopping\n",
      "Train on 232080 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 20s - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 2/1000\n",
      " - 20s - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 3/1000\n",
      " - 20s - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 4/1000\n",
      " - 20s - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 5/1000\n",
      " - 20s - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 6/1000\n",
      " - 20s - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 00006: early stopping\n",
      "Train on 246585 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 21s - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 2/1000\n",
      " - 21s - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 3/1000\n",
      " - 21s - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 4/1000\n",
      " - 21s - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 5/1000\n",
      " - 21s - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 6/1000\n",
      " - 21s - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 00006: early stopping\n",
      "Train on 261090 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 23s - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 2/1000\n",
      " - 23s - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 3/1000\n",
      " - 22s - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 4/1000\n",
      " - 22s - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 5/1000\n",
      " - 23s - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 6/1000\n",
      " - 23s - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 7/1000\n",
      " - 22s - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 00007: early stopping\n",
      "Train on 275595 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 24s - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 2/1000\n",
      " - 24s - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 3/1000\n",
      " - 24s - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 4/1000\n",
      " - 24s - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 5/1000\n",
      " - 24s - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 6/1000\n",
      " - 24s - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 7/1000\n",
      " - 24s - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 00007: early stopping\n",
      "Train on 290100 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 25s - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 2/1000\n",
      " - 25s - loss: 0.0018 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      " - 25s - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 4/1000\n",
      " - 25s - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 5/1000\n",
      " - 25s - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 6/1000\n",
      " - 25s - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 00006: early stopping\n",
      "Train on 290115 samples, validate on 96705 samples\n",
      "Epoch 1/1000\n",
      " - 25s - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 2/1000\n",
      " - 25s - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 3/1000\n",
      " - 25s - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 4/1000\n",
      " - 25s - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 5/1000\n",
      " - 25s - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 6/1000\n",
      " - 25s - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create neural net Aproch B\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "scores = {'train' : [] , 'valid' : []}\n",
    "count = 0\n",
    "while count < len(x_train):\n",
    "    count = count + int(len(x_train)/20)\n",
    "    if count > len(x_train):\n",
    "        count = len(x_train)\n",
    "    checkpointer = ModelCheckpoint(filepath = \"best_weights.hdf5\" , verbose = 0, save_best_only=True)\n",
    "    #step = Overfit(model,(x3,y3),(x_test,y_test))\n",
    "    history = model.fit(x_train[:count],y_train[:count],validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs= 1000)\n",
    "    model.load_weights('best_weights.hdf5')\n",
    "    scores['train'].append(scroe(model,x_train[:count],y_train[:count]))\n",
    "    scores['valid'].append(scroe(model,x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [0.0006894174422612531,\n",
       "  0.0007928300586005355,\n",
       "  0.0007123980236699579,\n",
       "  0.000637711134091723,\n",
       "  0.0006204756980351389,\n",
       "  0.0005515339538090247,\n",
       "  0.0006697198010537919,\n",
       "  0.0004825922095829105,\n",
       "  0.000582174729020668,\n",
       "  0.0005308514305412126,\n",
       "  0.000513929366049326,\n",
       "  0.0005113179363437359,\n",
       "  0.0005197146872431002,\n",
       "  0.0005022898507903717,\n",
       "  0.00046880386073766545,\n",
       "  0.00046535677352632643,\n",
       "  0.00043392744895265345,\n",
       "  0.0004328009498639762,\n",
       "  0.0003846223625246781,\n",
       "  0.00040675629093411825,\n",
       "  0.00038950071523358165],\n",
       " 'valid': [0.0016234941316374263,\n",
       "  0.0014166795925754094,\n",
       "  0.001168502145700856,\n",
       "  0.001075435603122954,\n",
       "  0.0010237319683573665,\n",
       "  0.0008479396101546133,\n",
       "  0.000775554521482813,\n",
       "  0.0008065767023421877,\n",
       "  0.0007031694328111238,\n",
       "  0.000682487978904911,\n",
       "  0.0006721472519518601,\n",
       "  0.0006411250710924854,\n",
       "  0.0007031694328111238,\n",
       "  0.0006721472519518601,\n",
       "  0.0005997621632800598,\n",
       "  0.0007031694328111238,\n",
       "  0.0006618065249986982,\n",
       "  0.0006307843441394345,\n",
       "  0.0006411250710924854,\n",
       "  0.0007238508867173366,\n",
       "  0.0007031694328111238]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting & Underfitting Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(scores['train'])\n",
    "plt.plot(scores['valid'])\n",
    "plt.title('Overfitting & Underfitting Graph')\n",
    "plt.ylabel('acc error')\n",
    "plt.xlabel('samples number')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
